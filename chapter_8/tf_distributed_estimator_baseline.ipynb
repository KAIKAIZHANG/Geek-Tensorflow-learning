{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 2.1.2\n",
      "numpy 1.19.1\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# GPU设置要在程序最开始的时候进行配置\n",
    "# 将模型的各个变量分布的情况进行打印输出\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 获取GPU的个数\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) # 设置内存自增长\n",
    "print(len(gpus))\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(logical_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  \"\"\"Loads the Fashion-MNIST dataset.\n",
    "\n",
    "  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\n",
    "  along with a test set of 10,000 images. This dataset can be used as\n",
    "  a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "  | Label | Description |\n",
    "  |:-----:|-------------|\n",
    "  |   0   | T-shirt/top |\n",
    "  |   1   | Trouser     |\n",
    "  |   2   | Pullover    |\n",
    "  |   3   | Dress       |\n",
    "  |   4   | Coat        |\n",
    "  |   5   | Sandal      |\n",
    "  |   6   | Shirt       |\n",
    "  |   7   | Sneaker     |\n",
    "  |   8   | Bag         |\n",
    "  |   9   | Ankle boot  |\n",
    "\n",
    "  Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "      **x_train, x_test**: uint8 arrays of grayscale image data with shape\n",
    "        (num_samples, 28, 28).\n",
    "\n",
    "      **y_train, y_test**: uint8 arrays of labels (integers in range 0-9)\n",
    "        with shape (num_samples,).\n",
    "\n",
    "  License:\n",
    "      The copyright for Fashion-MNIST is held by Zalando SE.\n",
    "      Fashion-MNIST is licensed under the [MIT license](\n",
    "      https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\n",
    "\n",
    "  \"\"\"\n",
    "  dirname = os.path.join('datasets', 'fashion-mnist')\n",
    "  # 数据下载到本地，提供一个本地的文件夹地址\n",
    "  base = '../chapter_2/data/'\n",
    "  # base = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\n",
    "  files = [\n",
    "      'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "      't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "  ]\n",
    "\n",
    "  paths = [base + f_name for f_name in files]\n",
    "  # for fname in files:\n",
    "  #   paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))\n",
    "\n",
    "  with gzip.open(paths[0], 'rb') as lbpath:\n",
    "    y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[1], 'rb') as imgpath:\n",
    "    x_train = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "\n",
    "  with gzip.open(paths[2], 'rb') as lbpath:\n",
    "    y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[3], 'rb') as imgpath:\n",
    "    x_test = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled  = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1,1)).reshape(-1, 28, 28, 1)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousRandomSeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# 生成dataset \n",
    "def make_dataset(images, labels, epochs, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    # prefetch预先生成多少个给训练做准备，属于加速的函数\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size).prefetch(50)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "train_dataset = make_dataset(x_train_scaled, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpaocazgwz\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "Executing op ReadVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Identity in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpaocazgwz', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=512, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=512, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "estimator = keras.estimator.model_to_estimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 6,939,018\n",
      "Trainable params: 6,939,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmpaocazgwz/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: /tmp/tmpaocazgwz/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 16 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpaocazgwz/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.305237, step = 0\n",
      "INFO:tensorflow:global_step/sec: 32.7726\n",
      "INFO:tensorflow:loss = 1.7103122, step = 100 (3.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7802\n",
      "INFO:tensorflow:loss = 1.1037227, step = 200 (2.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7918\n",
      "INFO:tensorflow:loss = 0.84464324, step = 300 (2.958 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.8289\n",
      "INFO:tensorflow:loss = 0.70810044, step = 400 (2.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7702\n",
      "INFO:tensorflow:loss = 0.6538073, step = 500 (2.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7798\n",
      "INFO:tensorflow:loss = 0.4509792, step = 600 (2.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.7928\n",
      "INFO:tensorflow:loss = 0.54878247, step = 700 (2.959 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.655\n",
      "INFO:tensorflow:loss = 0.57725704, step = 800 (2.971 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4941\n",
      "INFO:tensorflow:loss = 0.5695747, step = 900 (2.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.6832\n",
      "INFO:tensorflow:loss = 0.47260275, step = 1000 (2.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4376\n",
      "INFO:tensorflow:loss = 0.44248152, step = 1100 (2.990 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.5616\n",
      "INFO:tensorflow:loss = 0.3813749, step = 1200 (2.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.524\n",
      "INFO:tensorflow:loss = 0.6056844, step = 1300 (2.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.4944\n",
      "INFO:tensorflow:loss = 0.5309119, step = 1400 (2.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3359\n",
      "INFO:tensorflow:loss = 0.30493942, step = 1500 (3.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2808\n",
      "INFO:tensorflow:loss = 0.5413519, step = 1600 (3.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3986\n",
      "INFO:tensorflow:loss = 0.4552054, step = 1700 (2.992 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3041\n",
      "INFO:tensorflow:loss = 0.5228482, step = 1800 (3.003 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3268\n",
      "INFO:tensorflow:loss = 0.3735733, step = 1900 (3.001 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3325\n",
      "INFO:tensorflow:loss = 0.2905934, step = 2000 (3.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.3201\n",
      "INFO:tensorflow:loss = 0.44474036, step = 2100 (3.000 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1945\n",
      "INFO:tensorflow:loss = 0.34734696, step = 2200 (3.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1287\n",
      "INFO:tensorflow:loss = 0.34248096, step = 2300 (3.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2352\n",
      "INFO:tensorflow:loss = 0.40948457, step = 2400 (3.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2269\n",
      "INFO:tensorflow:loss = 0.3801636, step = 2500 (3.010 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.18\n",
      "INFO:tensorflow:loss = 0.2830624, step = 2600 (3.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0886\n",
      "INFO:tensorflow:loss = 0.4569829, step = 2700 (3.022 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.1153\n",
      "INFO:tensorflow:loss = 0.3951738, step = 2800 (3.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0715\n",
      "INFO:tensorflow:loss = 0.34975177, step = 2900 (3.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9451\n",
      "INFO:tensorflow:loss = 0.30728483, step = 3000 (3.035 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.0255\n",
      "INFO:tensorflow:loss = 0.29989147, step = 3100 (3.028 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.9327\n",
      "INFO:tensorflow:loss = 0.33187386, step = 3200 (3.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.983\n",
      "INFO:tensorflow:loss = 0.30468133, step = 3300 (3.032 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.7693\n",
      "INFO:tensorflow:loss = 0.21824127, step = 3400 (3.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.4639\n",
      "INFO:tensorflow:loss = 0.42933273, step = 3500 (3.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.086\n",
      "INFO:tensorflow:loss = 0.37162063, step = 3600 (3.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9102\n",
      "INFO:tensorflow:loss = 0.26551455, step = 3700 (3.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9523\n",
      "INFO:tensorflow:loss = 0.34171337, step = 3800 (3.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.724\n",
      "INFO:tensorflow:loss = 0.38151205, step = 3900 (3.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.9583\n",
      "INFO:tensorflow:loss = 0.28324646, step = 4000 (3.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.7645\n",
      "INFO:tensorflow:loss = 0.23085931, step = 4100 (3.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.1472\n",
      "INFO:tensorflow:loss = 0.32442868, step = 4200 (3.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3121\n",
      "INFO:tensorflow:loss = 0.30092603, step = 4300 (3.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3073\n",
      "INFO:tensorflow:loss = 0.26899558, step = 4400 (3.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.2305\n",
      "INFO:tensorflow:loss = 0.35139993, step = 4500 (3.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5618\n",
      "INFO:tensorflow:loss = 0.27894846, step = 4600 (3.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.3615\n",
      "INFO:tensorflow:loss = 0.2601483, step = 4700 (3.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.5165\n",
      "INFO:tensorflow:loss = 0.28565866, step = 4800 (3.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 31.6208\n",
      "INFO:tensorflow:loss = 0.28107074, step = 4900 (3.162 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmpaocazgwz/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.19018605.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f708c086358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(\n",
    "    input_fn= lambda : make_dataset(x_train_scaled, y_train, epochs, batch_size), max_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
