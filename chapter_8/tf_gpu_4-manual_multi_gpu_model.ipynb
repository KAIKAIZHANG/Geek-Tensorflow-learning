{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 2.1.2\n",
      "numpy 1.19.1\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# GPU设置要在程序最开始的时候进行配置\n",
    "# 将模型的各个变量分布的情况进行打印输出\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 获取GPU的个数\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) # 设置内存自增长\n",
    "print(len(gpus))\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(logical_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  \"\"\"Loads the Fashion-MNIST dataset.\n",
    "\n",
    "  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\n",
    "  along with a test set of 10,000 images. This dataset can be used as\n",
    "  a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "  | Label | Description |\n",
    "  |:-----:|-------------|\n",
    "  |   0   | T-shirt/top |\n",
    "  |   1   | Trouser     |\n",
    "  |   2   | Pullover    |\n",
    "  |   3   | Dress       |\n",
    "  |   4   | Coat        |\n",
    "  |   5   | Sandal      |\n",
    "  |   6   | Shirt       |\n",
    "  |   7   | Sneaker     |\n",
    "  |   8   | Bag         |\n",
    "  |   9   | Ankle boot  |\n",
    "\n",
    "  Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "      **x_train, x_test**: uint8 arrays of grayscale image data with shape\n",
    "        (num_samples, 28, 28).\n",
    "\n",
    "      **y_train, y_test**: uint8 arrays of labels (integers in range 0-9)\n",
    "        with shape (num_samples,).\n",
    "\n",
    "  License:\n",
    "      The copyright for Fashion-MNIST is held by Zalando SE.\n",
    "      Fashion-MNIST is licensed under the [MIT license](\n",
    "      https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\n",
    "\n",
    "  \"\"\"\n",
    "  dirname = os.path.join('datasets', 'fashion-mnist')\n",
    "  # 数据下载到本地，提供一个本地的文件夹地址\n",
    "  base = '../chapter_2/data/'\n",
    "  # base = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\n",
    "  files = [\n",
    "      'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "      't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "  ]\n",
    "\n",
    "  paths = [base + f_name for f_name in files]\n",
    "  # for fname in files:\n",
    "  #   paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))\n",
    "\n",
    "  with gzip.open(paths[0], 'rb') as lbpath:\n",
    "    y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[1], 'rb') as imgpath:\n",
    "    x_train = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "\n",
    "  with gzip.open(paths[2], 'rb') as lbpath:\n",
    "    y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[3], 'rb') as imgpath:\n",
    "    x_test = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled  = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1,1)).reshape(-1, 28, 28, 1)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousRandomSeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# 生成dataset \n",
    "def make_dataset(images, labels, epochs, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    # prefetch预先生成多少个给训练做准备，属于加速的函数\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size).prefetch(50)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "train_dataset = make_dataset(x_train_scaled, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:1\n",
      "Executing op RandomUniform in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Sub in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Mul in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Add in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarIsInitializedOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:2\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op LogicalNot in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op Assert in device /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "with tf.device(logical_gpus[0].name):\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.Conv2D(filters=32, kernel_size=3,\n",
    "                                  padding='same',\n",
    "                                  activation='relu',\n",
    "                                  input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3,\n",
    "                                  padding='same',\n",
    "                                  activation='relu',\n",
    "                                  input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.Conv2D(filters=64, kernel_size=3,\n",
    "                                  padding='same',\n",
    "                                  activation='relu',\n",
    "                                  input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "with tf.device(logical_gpus[1].name):\n",
    "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                                  padding='same',\n",
    "                                  activation='relu',\n",
    "                                  input_shape=(28, 28, 1)))\n",
    "    model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "with tf.device(logical_gpus[2]):\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 435,306\n",
      "Trainable params: 435,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op DatasetCardinality in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op OptimizeDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ModelDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op AnonymousIteratorV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op MakeIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Epoch 1/10\n",
      "Executing op Fill in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op AssignVariableOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op __inference_train_function_777 in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 1.4754 - accuracy: 0.4865\n",
      "Epoch 2/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.6699 - accuracy: 0.7548\n",
      "Epoch 3/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.5218 - accuracy: 0.8090\n",
      "Epoch 4/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.4475 - accuracy: 0.8353\n",
      "Epoch 5/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.4041 - accuracy: 0.8518\n",
      "Epoch 6/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.3783 - accuracy: 0.8615\n",
      "Epoch 7/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.3573 - accuracy: 0.8705\n",
      "Epoch 8/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.3407 - accuracy: 0.8756\n",
      "Epoch 9/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.3288 - accuracy: 0.8798\n",
      "Epoch 10/10\n",
      "429/429 [==============================] - 4s 8ms/step - loss: 0.3160 - accuracy: 0.8855\n",
      "Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=x_train_scaled.shape[0] // batch_size,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
