{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 2.1.2\n",
      "numpy 1.19.1\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "# 从本地保存数据文件加载数据\n",
    "with open(file='../chapter_2/data/california_housing.pkl', mode='rb') as f:\n",
    "    housing=pickle.load(f)\n",
    "# from sklearn.datasets import fetch_california_housing\n",
    "# housing = fetch_california_housing()\n",
    "print(housing.DESCR)\n",
    "print(housing.data.shape)\n",
    "print(housing.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8) (11610,)\n",
      "(3870, 8) (3870,)\n",
      "(5160, 8) (5160,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state = 7)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x_train_all, y_train_all, random_state = 11)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# metric使用\n",
    "# 对应元素差的平方求和，然后再求平均（单个数组中元素的个数）\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "print(metric([5., 4.], [2., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.75, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5, shape=(), dtype=float32)\n",
      "tf.Tensor(5.5, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(metric([5.], [2.])) \n",
    "# keras.metrics下面的指标是累积的，在当前batch上的结果会和之前的batch做平均。而keras.losses下面的不会。\n",
    "# 上一次的是6.5，这一次的是9，平均之后就是7.75\n",
    "print(metric([0.], [1.]))\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 具有累加功能，不想累加要reset_states\n",
    "metric.reset_states()\n",
    "metric([1.], [3.])\n",
    "print(metric.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  train mse: 1.3330629\t valid mse:  1.345685336597863\n",
      "Epoch 1  train mse: 1.2864465\t valid mse:  1.3862601861174022\n",
      "Epoch 2  train mse: 1.2705623\t valid mse:  1.3499298901068846\n",
      "Epoch 3  train mse: 1.3395284\t valid mse:  1.3604443347362967\n",
      "Epoch 4  train mse: nan\t valid mse:  nan\n",
      "Epoch 5  train mse: nan\t valid mse:  nan\n",
      "Epoch 6  train mse: nan\t valid mse:  nan\n",
      "Epoch 7  train mse: nan\t valid mse:  nan\n",
      "Epoch 8  train mse: nan\t valid mse:  nan\n",
      "Epoch 9  train mse: nan\t valid mse:  nan\n",
      "Epoch 10  train mse: nan\t valid mse:  nan\n",
      "Epoch 11  train mse: nan\t valid mse:  nan\n",
      "Epoch 12  train mse: nan\t valid mse:  nan\n",
      "Epoch 13  train mse: nan\t valid mse:  nan\n",
      "Epoch 14  train mse: nan\t valid mse:  nan\n",
      "Epoch 15  train mse: nan\t valid mse:  nan\n",
      "Epoch 16  train mse: nan\t valid mse:  nan\n",
      "Epoch 17  train mse: nan\t valid mse:  nan\n",
      "Epoch 18  train mse: nan\t valid mse:  nan\n",
      "Epoch 19  train mse: nan\t valid mse:  nan\n",
      "Epoch 20  train mse: nan\t valid mse:  nan\n",
      "Epoch 21  train mse: nan\t valid mse:  nan\n",
      "Epoch 22  train mse: nan\t valid mse:  nan\n",
      "Epoch 23  train mse: nan\t valid mse:  nan\n",
      "Epoch 24  train mse: nan\t valid mse:  nan\n",
      "Epoch 25  train mse: nan\t valid mse:  nan\n",
      "Epoch 26  train mse: nan\t valid mse:  nan\n",
      "Epoch 27  train mse: nan\t valid mse:  nan\n",
      "Epoch 28  train mse: nan\t valid mse:  nan\n",
      "Epoch 29  train mse: nan\t valid mse:  nan\n",
      "Epoch 30  train mse: nan\t valid mse:  nan\n",
      "Epoch 31  train mse: nan\t valid mse:  nan\n",
      "Epoch 32  train mse: nan\t valid mse:  nan\n",
      "Epoch 33  train mse: nan\t valid mse:  nan\n",
      "Epoch 34  train mse: nan\t valid mse:  nan\n",
      "Epoch 35  train mse: nan\t valid mse:  nan\n",
      "Epoch 36  train mse: nan\t valid mse:  nan\n",
      "Epoch 37  train mse: nan\t valid mse:  nan\n",
      "Epoch 38  train mse: nan\t valid mse:  nan\n",
      "Epoch 39  train mse: nan\t valid mse:  nan\n",
      "Epoch 40  train mse: nan\t valid mse:  nan\n",
      "Epoch 41  train mse: nan\t valid mse:  nan\n",
      "Epoch 42  train mse: nan\t valid mse:  nan\n",
      "Epoch 43  train mse: nan\t valid mse:  nan\n",
      "Epoch 44  train mse: nan\t valid mse:  nan\n",
      "Epoch 45  train mse: nan\t valid mse:  nan\n",
      "Epoch 46  train mse: nan\t valid mse:  nan\n",
      "Epoch 47  train mse: nan\t valid mse:  nan\n",
      "Epoch 48  train mse: nan\t valid mse:  nan\n",
      "Epoch 49  train mse: nan\t valid mse:  nan\n",
      "Epoch 50  train mse: nan\t valid mse:  nan\n",
      "Epoch 51  train mse: nan\t valid mse:  nan\n",
      "Epoch 52  train mse: nan\t valid mse:  nan\n",
      "Epoch 53  train mse: nan\t valid mse:  nan\n",
      "Epoch 54  train mse: nan\t valid mse:  nan\n",
      "Epoch 55  train mse: nan\t valid mse:  nan\n",
      "Epoch 56  train mse: nan\t valid mse:  nan\n",
      "Epoch 57  train mse: nan\t valid mse:  nan\n",
      "Epoch 58  train mse: nan\t valid mse:  nan\n",
      "Epoch 59  train mse: nan\t valid mse:  nan\n",
      "Epoch 60  train mse: nan\t valid mse:  nan\n",
      "Epoch 61  train mse: nan\t valid mse:  nan\n",
      "Epoch 62  train mse: nan\t valid mse:  nan\n",
      "Epoch 63  train mse: nan\t valid mse:  nan\n",
      "Epoch 64  train mse: nan\t valid mse:  nan\n",
      "Epoch 65  train mse: nan\t valid mse:  nan\n",
      "Epoch 66  train mse: nan\t valid mse:  nan\n",
      "Epoch 67  train mse: nan\t valid mse:  nan\n",
      "Epoch 68  train mse: nan\t valid mse:  nan\n",
      "Epoch 69  train mse: nan\t valid mse:  nan\n",
      "Epoch 70  train mse: nan\t valid mse:  nan\n",
      "Epoch 71  train mse: nan\t valid mse:  nan\n",
      "Epoch 72  train mse: nan nan\t valid mse:  nan\n",
      "Epoch 73  train mse: nan\t valid mse:  nan\n",
      "Epoch 74  train mse: nan\t valid mse:  nan\n",
      "Epoch 75  train mse: nan\t valid mse:  nan\n",
      "Epoch 76  train mse: nan\t valid mse:  nan\n",
      "Epoch 77  train mse: nan\t valid mse:  nan\n",
      "Epoch 78  train mse: nan\t valid mse:  nan\n",
      "Epoch 79  train mse: nan\t valid mse:  nan\n",
      "Epoch 80  train mse: nan\t valid mse:  nan\n",
      "Epoch 81  train mse: nan\t valid mse:  nan\n",
      "Epoch 82  train mse: nan\t valid mse:  nan\n",
      "Epoch 83  train mse: nan\t valid mse:  nan\n",
      "Epoch 84  train mse: nan\t valid mse:  nan\n",
      "Epoch 85  train mse: nan\t valid mse:  nan\n",
      "Epoch 86  train mse: nan\t valid mse:  nan\n",
      "Epoch 87  train mse: nan\t valid mse:  nan\n",
      "Epoch 88  train mse: nan\t valid mse:  nan\n",
      "Epoch 89  train mse: nan\t valid mse:  nan\n",
      "Epoch 90  train mse: nan\t valid mse:  nan\n",
      "Epoch 91  train mse: nan\t valid mse:  nan\n",
      "Epoch 92  train mse: nan\t valid mse:  nan\n",
      "Epoch 93  train mse: nan\t valid mse:  nan\n",
      "Epoch 94  train mse: nan\t valid mse:  nan\n",
      "Epoch 95  train mse: nan\t valid mse:  nan\n",
      "Epoch 96  train mse: nan\t valid mse:  nan\n",
      "Epoch 97  train mse: nan\t valid mse:  nan\n",
      "Epoch 98  train mse: nan\t valid mse:  nan\n",
      "Epoch 99  train mse: nan\t valid mse:  nan\n"
     ]
    }
   ],
   "source": [
    "# 1. batch 遍历训练集 metric\n",
    "#    1.1 自动求导\n",
    "# 2. epoch结束 验证集 metric\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(x_train_scaled) // batch_size\n",
    "optimizer = keras.optimizers.SGD()\n",
    "metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "def random_batch(x, y, batch_size=32):\n",
    "    idx = np.random.randint(0, len(x), size=batch_size)\n",
    "    return x[idx], y[idx]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu',\n",
    "                       input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    metric.reset_states()\n",
    "    for step in range(steps_per_epoch):\n",
    "        x_batch, y_batch = random_batch(x_train_scaled, y_train,\n",
    "                                        batch_size)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x_batch)\n",
    "#             y_pred = tf.squeeze(y_pred, 1)\n",
    "            loss = keras.losses.mean_squared_error(y_batch, y_pred)\n",
    "            metric(y_batch, y_pred)\n",
    "        grads = tape.gradient(loss, model.variables)\n",
    "        grads_and_vars = zip(grads, model.variables)\n",
    "        optimizer.apply_gradients(grads_and_vars)\n",
    "        print(\"\\rEpoch\", epoch, \" train mse:\",\n",
    "              metric.result().numpy(), end=\"\")\n",
    "    y_valid_pred = model(x_valid_scaled)\n",
    "    y_valid_pred = tf.squeeze(y_valid_pred, 1)\n",
    "    valid_loss = keras.losses.mean_squared_error(y_valid_pred, y_valid)\n",
    "    print(\"\\t\", \"valid mse: \", valid_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
