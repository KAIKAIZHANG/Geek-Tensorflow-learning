{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=4, releaselevel='final', serial=0)\n",
      "matplotlib 2.1.2\n",
      "numpy 1.19.1\n",
      "pandas 0.22.0\n",
      "sklearn 0.19.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# GPU设置要在程序最开始的时候进行配置\n",
    "# 将模型的各个变量分布的情况进行打印输出\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 获取GPU的个数\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True) # 设置内存自增长\n",
    "print(len(gpus))\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(logical_gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  \"\"\"Loads the Fashion-MNIST dataset.\n",
    "\n",
    "  This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories,\n",
    "  along with a test set of 10,000 images. This dataset can be used as\n",
    "  a drop-in replacement for MNIST. The class labels are:\n",
    "\n",
    "  | Label | Description |\n",
    "  |:-----:|-------------|\n",
    "  |   0   | T-shirt/top |\n",
    "  |   1   | Trouser     |\n",
    "  |   2   | Pullover    |\n",
    "  |   3   | Dress       |\n",
    "  |   4   | Coat        |\n",
    "  |   5   | Sandal      |\n",
    "  |   6   | Shirt       |\n",
    "  |   7   | Sneaker     |\n",
    "  |   8   | Bag         |\n",
    "  |   9   | Ankle boot  |\n",
    "\n",
    "  Returns:\n",
    "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "      **x_train, x_test**: uint8 arrays of grayscale image data with shape\n",
    "        (num_samples, 28, 28).\n",
    "\n",
    "      **y_train, y_test**: uint8 arrays of labels (integers in range 0-9)\n",
    "        with shape (num_samples,).\n",
    "\n",
    "  License:\n",
    "      The copyright for Fashion-MNIST is held by Zalando SE.\n",
    "      Fashion-MNIST is licensed under the [MIT license](\n",
    "      https://github.com/zalandoresearch/fashion-mnist/blob/master/LICENSE).\n",
    "\n",
    "  \"\"\"\n",
    "  dirname = os.path.join('datasets', 'fashion-mnist')\n",
    "  # 数据下载到本地，提供一个本地的文件夹地址\n",
    "  base = '../chapter_2/data/'\n",
    "  # base = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\n",
    "  files = [\n",
    "      'train-labels-idx1-ubyte.gz', 'train-images-idx3-ubyte.gz',\n",
    "      't10k-labels-idx1-ubyte.gz', 't10k-images-idx3-ubyte.gz'\n",
    "  ]\n",
    "\n",
    "  paths = [base + f_name for f_name in files]\n",
    "  # for fname in files:\n",
    "  #   paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))\n",
    "\n",
    "  with gzip.open(paths[0], 'rb') as lbpath:\n",
    "    y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[1], 'rb') as imgpath:\n",
    "    x_train = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "\n",
    "  with gzip.open(paths[2], 'rb') as lbpath:\n",
    "    y_test = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "  with gzip.open(paths[3], 'rb') as imgpath:\n",
    "    x_test = np.frombuffer(\n",
    "        imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)\n",
    "\n",
    "  return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28) (5000,)\n",
      "(55000, 28, 28) (55000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = load_data()\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape, y_valid.shape)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled  = scaler.fit_transform(\n",
    "    x_train.astype(np.float32).reshape(-1,1)).reshape(-1, 28, 28, 1)\n",
    "x_valid_scaled = scaler.transform(\n",
    "    x_valid.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)\n",
    "x_test_scaled = scaler.transform(\n",
    "    x_test.astype(np.float32).reshape(-1, 1)).reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op TensorSliceDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op ShuffleDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op RepeatDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op BatchDatasetV2 in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op PrefetchDataset in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "Executing op DeleteRandomSeedGenerator in device /job:localhost/replica:0/task:0/device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "# 生成dataset \n",
    "def make_dataset(images, labels, epochs, batch_size, shuffle=True):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    # prefetch预先生成多少个给训练做准备，属于加速的函数\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size).prefetch(50)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "train_dataset = make_dataset(x_train_scaled, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp_xqjvw26\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp_xqjvw26', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f89fc3feef0>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=128, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=256, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=512, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.Conv2D(filters=512, kernel_size=3,\n",
    "                              padding='same',\n",
    "                              activation='relu',\n",
    "                              input_shape=(28, 28, 1)))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics = [\"accuracy\"])\n",
    "\n",
    "# 转为estimator，并且定义为分布式的\n",
    "# estimator默认是没有做数据的并行的，所以在分布式下，数据的IO就会成为一个瓶颈，反而会出现比单节点的慢的情况\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "config = tf.estimator.RunConfig(\n",
    "    train_distribute = strategy)\n",
    "estimator = keras.estimator.model_to_estimator(model, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 14, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 6,939,018\n",
      "Trainable params: 6,939,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f8ab010ea60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f8ab010ea60> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp_xqjvw26/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: /tmp/tmp_xqjvw26/keras/keras_model.ckpt\n",
      "INFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\n",
      "INFO:tensorflow:Warm-started 16 variables.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp_xqjvw26/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.302002, step = 0\n",
      "INFO:tensorflow:global_step/sec: 24.1043\n",
      "INFO:tensorflow:loss = 2.0996966, step = 100 (4.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.065\n",
      "INFO:tensorflow:loss = 0.9619008, step = 200 (3.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1305\n",
      "INFO:tensorflow:loss = 0.92538714, step = 300 (3.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1565\n",
      "INFO:tensorflow:loss = 0.7190073, step = 400 (3.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1721\n",
      "INFO:tensorflow:loss = 0.75156826, step = 500 (3.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1913\n",
      "INFO:tensorflow:loss = 0.6477725, step = 600 (3.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1149\n",
      "INFO:tensorflow:loss = 0.67277706, step = 700 (3.688 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0501\n",
      "INFO:tensorflow:loss = 0.54741395, step = 800 (3.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1158\n",
      "INFO:tensorflow:loss = 0.58450973, step = 900 (3.686 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp_xqjvw26/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:Loss for final step: 0.5068882.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.EstimatorV2 at 0x7f89fc46ff98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(\n",
    "    input_fn= lambda : make_dataset(x_train_scaled, y_train, epochs, batch_size), max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
